
# MLOPS - ClassificaÃ§Ã£o de CrÃ©dito

Projeto de trabalho final realizado pelo aluno Luiz A. M. Garcia dentro da disciplina ECD15 de MLOPS.

O cÃ³digo do projeto estÃ¡ em https://github.com/lamgarcia/ufrgs-ecd15


## ğŸ“¦Dataset

O dataset escolhido Ã© de  **ClassificaÃ§Ã£o de CrÃ©dito** de cliente para compra de bens. O rÃ³tulo Ã© **Status** e tem o valor *good* (bom crÃ©dito) e *bad* (mau crÃ©dito).

RepositÃ³rio do dataset (buscar pelo item' credit_data'):
https://vincentarelbundock.github.io/Rdatasets/articles/data.html

Pode ser baixado diretamente do link: https://vincentarelbundock.github.io/Rdatasets/csv/modeldata/credit_data.csv

### Features 

1. rownames - NÃºmero ou identificador da linha.
2. **Status** - ClassificaÃ§Ã£o da situaÃ§Ã£o de crÃ©dito do cliente (*good*, *bad*) .
3. Seniority - Tempo de experiÃªncia profissional (nÃºmero em anos).
4. Home - SituaÃ§Ã£o de moradia (*rent, owner, parents, priv, other*)
5. Time - Tempo de relacionamento com a instituiÃ§Ã£o financeira (nÃºmero de meses).
6. Age - Idade do cliente (anos).
7. Marital - Estado Civil (*single, separated, married, widow*).
8. Records - Possui registros negativos de crÃ©dito (*yes, no*).
9. Job - Tipo de ocupaÃ§Ã£o profissional (*fixed, frelancer, partime*).
10. Expenses - Despesas mensais (dÃ³lares).
11. Income - Renda mensal (dÃ³lares).
12. Assets - valor dos ativos como bens  e investimentos(dÃ³lares).
13. Debt - DÃ­vida atual do cliente (dÃ³lares).
14. Aunt - Valor do crÃ©dito solicitado (dÃ³lares).
15. Price  - Valor total do bem adquirido (dÃ³lares).
### Valores limites

1. rownames: [1:4454]
2. Status: ['good', 'bad']
3. Seniority: [0:48]
4. Home: ['rent', 'owner', 'parents', 'priv', 'other', 'ignore']
5. Time: [6:72]
6. Age: [18:68]
7. Marital: ['married', 'widow', 'single', 'separated', 'divorced']
8. Records: ['no', 'yes']
9. Job: ['freelance', 'fixed', 'partime', 'others']
10. Expenses: [35:180]
11. Income: [6.0:959.0]
12. Assets: [0.0:300000.0]
13. Debt: [0.0:30000.0]
14. Amount: [100:5000]
15. Price: [105:11140]

### Resumo estatÃ­stico 

|       | rownames | Seniority | Time  | Age   | Expenses | Income | Assets  | Debt    | Amount  | Price   |
| ----- | -------- | --------- | ----- | ----- | -------- | ------ | ------- | ------- | ------- | ------- |
| count | 4454     | 4454      | 4454  | 4454  | 4454     | 4073   | 4407    | 4436    | 4454    | 4454    |
| mean  | 2227.5   | 7.99      | 46.44 | 37.08 | 55.57    | 141.69 | 5403.98 | 343.03  | 1038.92 | 1462.78 |
| std   | 1285.9   | 8.17      | 14.66 | 10.98 | 19.52    | 80.75  | 11574.4 | 1245.99 | 474.55  | 628.13  |
| min   | 1        | 0         | 6     | 18    | 35       | 6      | 0       | 0       | 100     | 105     |
| 25%   | 1114.25  | 2         | 36    | 28    | 35       | 90     | 0       | 0       | 700     | 1117.25 |
| 50%   | 2227.5   | 5         | 48    | 36    | 51       | 125    | 3000    | 0       | 1000    | 1400    |
| 75%   | 3340.75  | 12        | 60    | 45    | 72       | 170    | 6000    | 0       | 1300    | 1691.5  |
| max   | 4454     | 48        | 72    | 68    | 180      | 959    | 300000  | 30000   | 5000    | 11140   |


## ğŸ“ Estrutura do projeto

```bash
â”œâ”€â”€ README.md                  # documentaÃ§Ã£o do projeto
â”œâ”€â”€ requirements.txt           # imports do python
â”œâ”€â”€ config_pipeline.json       # configuraÃ§Ãµes principais do pipeline
â”œâ”€â”€ run_training_serving.py    # run mlflow e codigo de treinamento e serving 
â”œâ”€â”€ run_simulation_drift.py    # run simula inferencia, monitor de drift e trigger
â”œâ”€â”€ stop_mlflow.py             # codigo auxiliar para parar mlflow se preciso
â”œâ”€â”€ mlflow.db                  # base dados do mlflow criada na execuÃ§Ã£o do mlflow

â”œâ”€â”€ data                       
â”‚   â”œâ”€â”€ raw                    # dataset principal do modelo
â”‚   â”‚   â””â”€â”€ credit_data.csv
â”‚   â””â”€â”€ inferences             # dataset com inferÃªncias simuladas
â”‚       â””â”€â”€ credit_data_inferences_log.csv
 
â”œâ”€â”€ src
    â”œâ”€â”€ experiments
    â”‚   â”œâ”€â”€ credit_model_experiments.py # experimentos de treinamento dos models
    â”‚   â””â”€â”€ credit_model_promote.py     # promove modelo campeÃ£o a produÃ§Ã£o
	â”œâ”€â”€ serve
    â”‚   â””â”€â”€ credit_model_serve.py       # sobe serviÃ§o de api com modelo campeÃ£o 
	â”œâ”€â”€ monitor
    â”‚   â””â”€â”€ monitor_drift.py            # monitora drifts e salva em \reports
    â”œâ”€â”€ simulation
    â”‚   â””â”€â”€ simulation.py               # cria dataset de inferencias simuladas
    â””â”€â”€ triggers
        â””â”€â”€ retraining_trigger.py       # verifica \reports e aciona retreinamento

â”œâ”€â”€ reports                     # pasta com reports de drift do evidently
â”‚   â”œâ”€â”€ report_classdrift.html
â”‚   â”œâ”€â”€ report_classdrift.json  # class drifts em json para a trigger
â”‚   â”œâ”€â”€ report_datadrift.html
â”‚   â””â”€â”€ report_datadrift.json   # data drifts em json para a trigger

â”œâ”€â”€ runs   
â”‚   â””â”€â”€ runs.log                # logs dos pythons executados no pipeline (\src)
        
â”œâ”€â”€ mlruns/                    # runs do mlflow, criado apÃ³s inicializaÃ§Ã£o
```



## ğŸ“Arquivo de configuraÃ§Ã£o (config_pipeline.json)

Arquivo **config_pipeline.json** Ã© um arquivo de configuraÃ§Ã£o utilizado por vÃ¡rios cÃ³digos do modelo. Facilita alteraÃ§Ã£o e parÃ¢metros para  execuÃ§Ã£o do pipeline e permite maior flexibilidade sem alterar os cÃ³digos.  AtravÃ©s dele Ã© possÃ­vel definir a acurÃ¡cia do dataset da simulaÃ§Ã£o para que possa ser disparado o trigger de re-treinamento em caso de drift superior. 


```bash
config_pipeline.json:

{
   "mlflow":{
      "mlflow_uri":"sqlite:///mlflow.db",
      "mlflow_experiment":"CreditData_Experiments"
   },
   "files":{
      "dataset":"data/raw/credit_data.csv",
      "datadrift_html":"reports/report_datadrift.html",
      "datadrift_json":"reports/report_datadrift.json",
      "classdrift_html":"reports/report_classdrift.html",
      "classdrift_json":"reports/report_classdrift.json",
      "inferences_log":"data/inferences/credit_data_inferences_log.csv",
      "runs_log":"runs/runs.log"
   },
   "experiments":{
      "staging_threshold":0.70
   },
   "drift":{
      "min_f1_score":0.65,
      "min_data_share":1,
      "code_retraining":"run_training_serving.py"
   },
   "simulation":{
       "acuracia":0.5,
       "amostras":2000
   }
}
```

## ğŸ”„Pipeline
```mermaid
flowchart TD

    subgraph Train [run_training_serving.py]
        A1[â–¶ï¸Iniciar MLflow]
        A2[[âš™ï¸Treinamento, Versionamento e Armazenamento <br>src/experiments/<br>credit_model_experiments.py]]
        A3[[ğŸ“ŠAvaliaÃ§Ã£o e PromoÃ§Ã£o do CampeÃ£o<br>src/experiments/<br>credit_model_promote.py]]
        A4[[ğŸš€ImplantaÃ§Ã£o<br>src/serve/<br>credit_model_serve.py]]
        A1 --> A2 --> A3 --> A4 
    end
    

    subgraph Drift [run_simulation_drift.py]
        B1[[ğŸ§ªSimular InferÃªncias<br>src/simulation/<br>simulation.py]]
        B2[[ğŸ”Monitorar Drift<br>src/monitor/<br>monitor_drift.py]]
        B3[ğŸ¯Trigger de Retreinamento<br>src/triggers/<br>retraining_trigger.py]
        C1{{Tem Drift?}}
        B1 --> B2 
        B3 --> C1 --> A2
        
    end

    S1[/API - Modelo em ProduÃ§Ã£o/]
    D1[(ğŸ“¦Dataset<br> raw/credit_data.csv)] 
    D2[(ğŸ“¦Dataset simulado<br>inferences/<br>credit_data_inferences_log.csv)]
    D3[(ğŸ“„Reports de Drifts<br> reports/)]
    D4[(ğŸ›¢ï¸mlflow.db)]
    D5[(ğŸ“„config_pipeline.json)]

	A1 --> D4
	A4 --> S1
	S1 --> B1
    D1 --> A2
    B1 --> D2
    D1 --> B2
    D2 --> B2
    B2 --> D3
    D3 --> B3

```
## ğŸ› ï¸Ferramentas 


No Pipeline foram utilizadas as seguintes Ferramentas:
- Rastreamento, Versionamento, e Armazenamento de Artefatos: MLFlow 
- Treinamento e mÃ©tricas dos modelos: SKLearn e XGboost 
- DisponibilizaÃ§Ã£o do Modelo via API: MLFlow
- Monitoramento de Drifts: Evidently AI
- Log das etapas da execuÃ§Ã£o: Logging
- Controle de versÃ£o do cÃ³digo: GitLab  

## ğŸ¤–Modelos, Resultados e MÃ©tricas
 
Como Ã© um problema de classificaÃ§Ã£o de crÃ©dito, foram utilizados os modelos Random Forest, XGBoost e Logistic Regression com parÃ¢metros diversos para avaliaÃ§Ã£o. Abaixo os F-Scores de uma execuÃ§Ã£o de treinamento.

|                                                                              |                    |
| ---------------------------------------------------------------------------- | ------------------ |
| **Modelo e parÃ¢metros**                                                      | **f1-score**       |
| RandomForest_{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10} | 0.859896219421794  |
| RandomForest_{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}  | 0.8584202682563339 |
| XGBoost_{'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.2}          | 0.8564885496183207 |
| RandomForest_{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10}  | 0.8558692421991084 |
| RandomForest_{'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 10}  | 0.8552036199095022 |
| XGBoost_{'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}          | 0.8551829268292683 |
| LogisticRegression_{'C': 3.0, 'penalty': 'l2', 'solver': 'lbfgs'}            | 0.8550404709345106 |
| XGBoost_{'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.2}          | 0.8549382716049383 |
| LogisticRegression_{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}            | 0.8548148148148148 |
| RandomForest_{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}  | 0.8537666174298375 |
| RandomForest_{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}   | 0.85331347728965   |
| RandomForest_{'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 10}  | 0.8530734632683659 |
| RandomForest_{'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 2}  | 0.8526315789473684 |
| RandomForest_{'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 5}   | 0.8522130532633159 |
| LogisticRegression_{'C': 2.0, 'penalty': 'l2', 'solver': 'lbfgs'}            | 0.8518242740134029 |
| XGBoost_{'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.2}          | 0.8516228748068007 |
| RandomForest_{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 10} | 0.8513513513513513 |
| XGBoost_{'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.1}          | 0.8509984639016898 |
| RandomForest_{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 5}  | 0.8507126781695424 |
| XGBoost_{'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.1}          | 0.850609756097561  |
| LogisticRegression_{'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}            | 0.8505917159763313 |
| XGBoost_{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}          | 0.8503453568687643 |
| RandomForest_{'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 5}  | 0.8502994011976048 |
| XGBoost_{'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.1}          | 0.8498845265588915 |
| RandomForest_{'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 10} | 0.8489857250187829 |
| RandomForest_{'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 5}   | 0.8489425981873112 |
| RandomForest_{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}   | 0.8489314664701547 |
| XGBoost_{'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.2}          | 0.8488104374520338 |
| XGBoost_{'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.3}          | 0.8485780169100692 |
| LogisticRegression_{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}           | 0.8481291269258987 |
| XGBoost_{'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.3}          | 0.847457627118644  |
| XGBoost_{'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.2}         | 0.8472755180353031 |
| XGBoost_{'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.1}          | 0.8465690053970701 |
| RandomForest_{'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 2}   | 0.8457486832204665 |
| XGBoost_{'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.3}          | 0.8457405986185725 |
| XGBoost_{'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.2}          | 0.8457405986185725 |
| RandomForest_{'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 2}  | 0.8456883509833586 |
| XGBoost_{'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.1}         | 0.8453292496171516 |
| XGBoost_{'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.3}          | 0.8450920245398773 |
| XGBoost_{'n_estimators': 150, 'max_depth': 12, 'learning_rate': 0.1}         | 0.8448540706605223 |
| RandomForest_{'n_estimators': 50, 'max_depth': 30, 'min_samples_split': 2}   | 0.8444108761329305 |
| XGBoost_{'n_estimators': 150, 'max_depth': 12, 'learning_rate': 0.2}         | 0.8440366972477065 |
| XGBoost_{'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.3}         | 0.8437259430331023 |
| XGBoost_{'n_estimators': 150, 'max_depth': 12, 'learning_rate': 0.3}         | 0.8433179723502304 |
| XGBoost_{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.3}          | 0.8433179723502304 |
| XGBoost_{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.2}          | 0.8428351309707242 |
| XGBoost_{'n_estimators': 100, 'max_depth': 12, 'learning_rate': 0.2}         | 0.8421052631578947 |
| XGBoost_{'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.3}         | 0.8417818740399385 |
| XGBoost_{'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.3}          | 0.8413793103448276 |
| XGBoost_{'n_estimators': 200, 'max_depth': 12, 'learning_rate': 0.1}         | 0.8407350689127105 |

## ğŸš€ExecuÃ§Ã£o do Pipeline

##### Clonar o projeto
O projeto foi executado em ambiente Windows, pode ser necessÃ¡rio ajustes para Linux ou Mac.

##### InstalaÃ§Ã£o dos MÃ³dulos do Python** 
``` bass
python -m pip install --upgrade pip
pip install -r requirements.txt
```
##### Setar a variÃ¡vel de ambiente para execuÃ§Ã£o do MLFLOW (no Windows)
``` bash
setx MLFLOW_TRACKING_URI "sqlite:///mlflow.db"
```
##### Iniciar serviÃ§o do MLFLOW
``` bash
mlflow ui --backend-store-uri sqlite:///mlflow.db
```
##### Treinar e Servir
```bash
python run_training_serving.py
```
##### Simular serving, monitoramento e trigger de retreinamento
``` bash
python run_simulation_drift.py
```


## âœ…ConsideraÃ§Ãµes 

Neste trabalho foi implementado um Pipeline de MLOPS completo: 
- treinamento
- versionamento
- armazenamento de modelo
- avaliaÃ§Ã£o dos modelos
- promoÃ§Ã£o do campeÃ£o em f1-score
- implantaÃ§Ã£o do modelo vencedor  via API
- armazenamento das inferÃªncias do modelo em produÃ§Ã£o
- monitoramento de drift
- trigger para retreinamento em caso de drifts. 

TambÃ©m foi utilizado arquivo de configuraÃ§Ã£o global para facilitar a execuÃ§Ã£o do pipeline com outros parÃ¢metros e log das execuÃ§Ãµes em arquivo especÃ­fico para consulta posterior.
